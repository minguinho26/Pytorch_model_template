# Pytorch_model_template

Note : í˜„ì¬ ì½”ë“œ ìˆ˜ì • í›„ ì„±ëŠ¥ í™•ì¸ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¶”í›„ ìˆ˜ì •ëœ ì½”ë“œì™€ í•¨ê»˜ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸ í•˜ê² ìŠµë‹ˆë‹¤.

ì œì‘ì : ê¹€ë¯¼ê·œ <br>
ë¦¬í¬ì§€í† ë¦¬ ìƒì„±ì¼ : 22.4.16

## ì„¤ëª…
íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•´ ì œì‘í•œ ë„¤íŠ¸ì›Œí¬(MLP, CNN ë“±)ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì œì‘í•˜ëŠ” í…œí”Œë¦¿. <br>
22.4.16 ê¸°ì¤€ìœ¼ë¡œ 3ê°€ì§€ ìœ í˜•(Linear, CNN, residual CNN)ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

* util.py : ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë“¤ì„ ëª¨ì•˜ìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ íŒŒì¼ì— ì í˜€ìˆëŠ” ì£¼ì„ì„ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

## êµ¬ì„±(22.4.18 ê¸°ì¤€)
ğŸ“ main <br>
â””ğŸ“Basic_model <br>
â €â””normal_MLP.py <br>
â””ğŸ“Image_Classification <br>
â €â””ğŸ“CNN <br>
â €â €â””normal_CNN.py <br>
â €â €â””residual_CNN.py <br>
â €â””ğŸ“Linear <br>
â €â €â””MLP_Mixer.py <br>
â””ğŸ“util <br>
â €â””util.py <br>

### **<1> Basic model**
ê°€ì¥ ê¸°ë³¸ì ì¸ MLPê°€ ìˆìŠµë‹ˆë‹¤. 

1. Linear : ì„ í˜• ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” nn.Linear ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Basic_model.normal_MLP import *
 
    model = normal_MLP(input_size = 64, neural_list = [64, 64, 128, 128],  mid_activation_func = 'leaky_relu',  last_activateion_func = 'softmax', batch_normalization_use = False)
    ~~~

### **<2> Image Classification**
ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¼ì„ ìˆ˜í–‰í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

#### **<2-1> CNN**
CNNìœ¼ë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ë“¤ì…ë‹ˆë‹¤. 

1. normal_CNN : Covolution ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” CNN ì¤‘ ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœë¥¼ ê°€ì§„ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. <br> 
   ì‚¬ìš© ì˜ˆ)
    ~~~python
    # ì¼ë°˜ì ì¸ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.normal_CNN import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224) # ë„¤íŠ¸ì›Œí¬ì— ë„£ì„ ì´ë¯¸ì§€ì˜ í¬ê¸°
    kernal_list_normal_CNN = [16, 16,'p', 32, 32, 'p', 64, 64, 'p', 128, 128, 'p', 256, 256] # ìˆ«ìëŠ” Conv2dì˜ ì±„ë„ ê°œìˆ˜, 'p'ëŠ” poolingì„ ì˜ë¯¸í•©ë‹ˆë‹¤
    classes_num = 10 # ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜

    normal_cnn = normal_CNN(input_size = image_size, kernal_list = kernal_list_normal_CNN, num_classes = classes_num, activation_func = 'relu', batch_normalization_use = True, device = 'cuda')


    ~~~
2. residual_CNN : Skip connectionì„ ìˆ˜í–‰í•˜ëŠ” CNNì…ë‹ˆë‹¤. ResNetì—ì„œ ì œì•ˆí•œ residual blockì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    ~~~python
    # Residual CNN, ê·¸ëŸ¬ë‹ˆê¹Œ ResNet ê³„ì—´ì˜ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.residual_CNN import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224)
    kernal_list_residual_CNN = [32, 32, 64, 64, 64, 64, 128, 128, 128]
    classes_num = 10
    
    residual_cnn = residual_CNN(input_size = image_size, kernal_list = kernal_list_residual_CNN, num_classes = classes_num, Residual_Block_size = 'small')

    ~~~


#### **<2-2> Linear**
MLPë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤.

1. MLP-Mixer : MLPë§Œ ê°€ì§€ê³  ì´ë¯¸ì§€ì˜ classificationì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ìì„¸í•œ ì„¤ëª…ì€ MLP.MLP_Mixer.pyì— ìˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Linear.MLP_Mixer import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224)
    mlp_mixer = MLP_Mixer(input_size=image_size, patch_size=4, C=128, N=6, classes_num=classes_num).to('cuda')
    ~~~

## ì‹¤í—˜ ì„¸íŒ…

ì•„ë˜ ì¡°ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 
> ì‹¤í—˜ì„ ìˆ˜í–‰í•œ ì½”ë“œëŠ” model.ipynbì´ë¯€ë¡œ ìì„¸í•œ ì •ë³´ëŠ” í•´ë‹¹ ì£¼í”¼í„° ë…¸íŠ¸ë¶  íŒŒì¼ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br>

### Training setting

~~~python
# Optimizer : Adam
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)
# Gradient Cliping
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
# Epoch
EPOCH = 600
# Loss function
loss_function = torch.nn.CrossEntropyLoss()
~~~

<br>

### Dataset : CIFAR 10(train, test)
~~~python
batch_size = 500

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root='./cifar', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./cifar', train=False, download=True, transform=transform)

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=False, drop_last=True)

test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=False, drop_last=True)
~~~

<br>

### Model ì •ë³´

1. normal_cnn : ì¼ë°˜ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” CNN
2. residual_cnn : Residual blockìœ¼ë¡œ ì„¤ê³„ëœ CNN
3. mlp_mixer_S4 : Image patchê°€ (4,4)ê³  Cë¥¼ 128ë¡œ ì„¤ì •í•œ MLP-Mixer
4. mlp_mixer_S2 : Image patchê°€ (2,2)ê³  Cë¥¼ 128ë¡œ ì„¤ì •í•œ MLP-Mixer
5. mlp_mixer_B4 : Image patchê°€ (4,4)ê³  Cë¥¼ 192ë¡œ ì„¤ì •í•œ MLP-Mixer
6. mlp_mixer_B2 : Image patchê°€ (2,2)ê³  Cë¥¼ 192ë¡œ ì„¤ì •í•œ MLP-Mixer

<br>

### Model Parameter ì •ë³´

| model        | parameter_num |
|--------------|---------------|
| normal_cnn   | 1,183,322       |
| residual_cnn | 1,134,026       |
| mlp_mixer_S4 | 273,674        |
| mlp_mixer_S2 | 1,062,026       |
| mlp_mixer_B4 | 698,186        |
| mlp_mixer_B2 | 1,756,106       |

<br>

## ì‹¤í—˜ ê²°ê³¼

<img width="910" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-30 á„‹á…©á„’á…® 5 12 02" src="https://user-images.githubusercontent.com/50979281/166097671-4b8d3b73-d323-4557-9fff-c0a1decaad4f.png">

<br>

<img width="913" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-30 á„‹á…©á„’á…® 5 12 13" src="https://user-images.githubusercontent.com/50979281/166097668-07357d0d-66db-4359-9a53-357a870d4ae1.png">

normal_cnnì´ ì œì¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. CIFAR10 ë°ì´í„°ì…‹ì˜ í¬ê¸°ê°€ ì‘ì•„ì„œ ê·¸ëŸ° ê²ƒìœ¼ë¡œ ì¶”ì •í•˜ê³  ìˆìŠµë‹ˆë‹¤.
