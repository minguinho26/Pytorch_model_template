# Pytorch_model_template

Note : í˜„ì¬ ì½”ë“œ ìˆ˜ì • í›„ ì„±ëŠ¥ í™•ì¸ì„ í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì¶”í›„ ìˆ˜ì •ëœ ì½”ë“œì™€ í•¨ê»˜ ê²°ê³¼ë¥¼ ì—…ë°ì´íŠ¸ í•˜ê² ìŠµë‹ˆë‹¤.

ì œì‘ì : ê¹€ë¯¼ê·œ <br>
ë¦¬í¬ì§€í† ë¦¬ ìƒì„±ì¼ : 22.4.16

## ì„¤ëª…
íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•´ ì œì‘í•œ ë„¤íŠ¸ì›Œí¬(MLP, CNN ë“±)ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì œì‘í•˜ëŠ” í…œí”Œë¦¿. <br>
22.4.16 ê¸°ì¤€ìœ¼ë¡œ 3ê°€ì§€ ìœ í˜•(Linear, CNN, residual CNN)ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

* util.py : ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë“¤ì„ ëª¨ì•˜ìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ íŒŒì¼ì— ì í˜€ìˆëŠ” ì£¼ì„ì„ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

## êµ¬ì„±(22.4.18 ê¸°ì¤€)
ğŸ“ main <br>
â””ğŸ“Basic_model <br>
â €â””normal_MLP.py <br>
â””ğŸ“Image_Classification <br>
â €â””ğŸ“CNN <br>
â €â €â””normal_CNN.py <br>
â €â €â””dense_CNN.py <br>
â €â €â””residual_CNN.py <br>
â €â””ğŸ“Linear <br>
â €â €â””MLP_Mixer.py <br>
â””ğŸ“util <br>
â €â””util.py <br>

### **<1> Basic model**
ê°€ì¥ ê¸°ë³¸ì ì¸ MLPê°€ ìˆìŠµë‹ˆë‹¤. 

1. Linear : ì„ í˜• ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” nn.Linear ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Basic_model.normal_MLP import *

    # ê¸°ë³¸ì ìœ¼ë¡œ ì—°ì‚° ë„ì¤‘ì— ì‚¬ìš©í•˜ëŠ” í™œì„±í™” í•¨ìˆ˜ëŠ” ReLU, ì—°ì‚°ì˜ ë§ˆì§€ë§‰ì— ì‚¬ìš©í•˜ëŠ” í™œì„±í™” í•¨ìˆ˜ëŠ” Sigmoid í•¨ìˆ˜ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. ê·¸ë¦¬ê³  Batch Normalizationë„ ì‚¬ìš©í•˜ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤. ì´ ì„¤ì •ë“¤ì€ ì´ˆê¸°í™” í•  ë•Œ ì…ë ¥í•˜ëŠ” ê°’ì„ í†µí•´ ê°œì¸ì ìœ¼ë¡œ ë³€ê²½í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
    model = normal_MLP(input_size = 64, neural_list = [64, 64, 128, 128],  mid_activation_func = 'leaky_relu',  last_activateion_func = 'softmax', batch_normalization_use = False)
    ~~~

### **<2> Image Classification**
ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¼ì„ ìˆ˜í–‰í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

#### **<2-1> CNN**
CNNìœ¼ë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ë“¤ì…ë‹ˆë‹¤. 

1. normal_CNN : Covolution ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” CNN ì¤‘ ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœë¥¼ ê°€ì§„ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. <br> 
   ì‚¬ìš© ì˜ˆ)
    ~~~python
    # ì¼ë°˜ì ì¸ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.normal_CNN import *

    # input_size : ì…ë ¥ë˜ëŠ” featureì˜ í¬ê¸°ì…ë‹ˆë‹¤. ì˜ˆ) (3, 224, 224)
    # kernal_list : Convolutional layerë“¤ì´ ì‚¬ìš©í•  ì»¤ë„ì˜ ê°œìˆ˜. pëŠ” poolingì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. 
    # num_classes : ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
    # batch_normalization_use : ì—°ì‚° ì¤‘ê°„ì¤‘ê°„ì— Batch Normalizatoinì„ ì‚¬ìš©í• ì§€ ë§ì§€ ê²°ì •í•©ë‹ˆë‹¤.
    # device : ë„¤íŠ¸ì›Œí¬ë¥¼ ê°€ì§€ê³  ì—°ì‚°í•  ì¥ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

    # ì‚¬ìš© ì˜ˆ
    model = normal_CNN(input_size = (3, 224, 224), kernal_list = [64, 64, 'p', 128, 128], num_classes = 1000, activation_func = 'leaky_relu', batch_normalization_use = False, device = 'cuda')
    ~~~
2. residual_CNN : Skip connectionì„ ìˆ˜í–‰í•˜ëŠ” CNNì…ë‹ˆë‹¤. ResNetì—ì„œ ì œì•ˆí•œ residual blockì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    ~~~python
    # Residual CNN, ê·¸ëŸ¬ë‹ˆê¹Œ ResNet ê³„ì—´ì˜ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.residual_CNN import *

    # input_size : ì…ë ¥ë˜ëŠ” featureì˜ í¬ê¸°ì…ë‹ˆë‹¤. ì˜ˆ) (3, 224, 224) 
    # kernal_list : Convolutional layerë“¤ì´ ì‚¬ìš©í•  ì»¤ë„ì˜ ê°œìˆ˜. residual_CNNì€ ì»¤ë„ì´ ë³€ê²½ë  ë•Œë§ˆë‹¤ poolingì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.  
    # num_classes : ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
    # Residual_Block_size : smallì´ë©´ 2ê°œì˜ Convolutional layerë¡œ êµ¬ì„±ëœ residual block ì‚¬ìš©, bigì´ë©´ 3ê°œì˜ Convolutional layerë¡œ êµ¬ì„±ëœ residual block ì‚¬ìš©
    # device : ë„¤íŠ¸ì›Œí¬ë¥¼ ê°€ì§€ê³  ì—°ì‚°í•  ì¥ì¹˜ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.

    # ResNet ë…¼ë¬¸ì— ë”°ë¥´ë©´ 50ì¸µ ì´ìƒì˜ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ê³„í•  ë•ŒëŠ” 3ê°œì˜ Convolutional layerë¡œ êµ¬ì„±ëœ residual blockì„ ì“°ê³  ê·¸ë³´ë‹¤ ì‘ì€ ë„¤íŠ¸ì›Œí¬ë¥¼ ì„¤ê³„í•  ë•ŒëŠ” 2ê°œì˜ Convolutional layerë¡œ êµ¬ì„±ëœ residual blockì„ ì‚¬ìš©í•©ë‹ˆë‹¤. 
    model = residual_CNN(input_size = (3, 224, 224), kernal_list = [64, 64, 128, 128], num_classes = 1000, Residual_Block_size = 'big', device = 'cuda')
    ~~~

3. dense_CNN : DenseNetì—ì„œ ì œì•ˆí•œ Dense blockì„ ì‚¬ìš©í•´ êµ¬ì„±í•œ CNNì…ë‹ˆë‹¤. 
    ~~~python
    # Dense CNN, DenseNetì„ êµ¬ì„±í•˜ëŠ” Dense blockìœ¼ë¡œ êµ¬ì„±ëœ CNN
    from CNN.dense_CNN import *

    # input_size : ì…ë ¥ë˜ëŠ” featureì˜ í¬ê¸°ì…ë‹ˆë‹¤. ì˜ˆ) (3, 224, 224)
    # dense_block_first_channel. ë§¨ì²˜ìŒ Dense Blockì´ ì‚¬ìš©í•˜ëŠ” ì»¤ë„ì˜ ê°œìˆ˜. DenseNetì€ ë‹¤ìŒ Dense blockìœ¼ë¡œ ë„˜ì–´ê°ˆ ë•Œë§ˆë‹¤ ì±„ë„ì˜ í¬ê¸°ë¥¼ 2ë°°ì”© ëŠ˜ë¦½ë‹ˆë‹¤. ê·¸ë˜ì„œ ë§¨ì²˜ìŒ channel, ì¦‰ kernalì˜ ê°’ë§Œ ë°›ìŠµë‹ˆë‹¤.
    # dense_block_layer_list. ê° Dense blockì—ì„œ ì“°ì´ëŠ” residual blockì˜ ê°œìˆ˜ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ë‹¤ì‹œë§í•´ len(dense_block_layer_list) = CNNì´ ì‚¬ìš©í•˜ëŠ” Dense blockì˜ ê°œìˆ˜ì…ë‹ˆë‹¤.
    # is_flatten : ì—°ì‚°ì˜ ë§ˆì§€ë§‰ì— 1ì°¨ì› ë²¡í„°ë¡œ ë§Œë“¤ì–´ì£¼ëŠ” nn.Flatten()ì„ ì‚¬ìš©í•  ê²ƒì¸ì§€ ë§ì§€ ê²°ì •í•©ë‹ˆë‹¤. 
    model = dense_CNN(input_size = (3, 224, 224), dense_block_first_channel = 64, dense_block_layer_list = [16, 32, 8], num_classes = 1000, device = 'cuda')
    ~~~

#### **<2-2> Linear**
MLPë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤.

1. MLP-Mixer : MLPë§Œ ê°€ì§€ê³  ì´ë¯¸ì§€ì˜ classificationì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ìì„¸í•œ ì„¤ëª…ì€ MLP.MLP_Mixer.pyì— ìˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Linear.MLP_Mixer import *

    # image_size : ì…ë ¥ê°’ìœ¼ë¡œ ë„£ì„ ì´ë¯¸ì§€ì˜ í¬ê¸°. 
    # patch_size : MLP-Mixerê°€ ì‚¬ìš©í•  patchì˜ í¬ê¸°. MLP-MixerëŠ” ì´ë¯¸ì§€ë¥¼ patchë‹¨ìœ„ë¡œ ë‚˜ëˆˆ ë‹¤ìŒ toeknìœ¼ë¡œ embeddingí•˜ê³  mixer-layerì— ë„£ì–´ì¤ë‹ˆë‹¤.
    # C : desired hidden dimension. ê°œì¸ì ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ê°’ì…ë‹ˆë‹¤. 
    # N : MLP-Mixerê°€ ì‚¬ìš©í•  Mixer-Layerì˜ ê°œìˆ˜.
    # classes_num : MLP_Mixerê°€ ë¶„ë¥˜í•  í´ë˜ìŠ¤ì˜ ê°œìˆ˜.

    image_size = (3, 224, 224)
    mixer = MLP_Mixer(input_size=image_size, patch_size=32, C=512, N=8, classes_num=1000) # ì…ë ¥ê°’ìœ¼ë¡œ ë“¤ì–´ê°€ëŠ” ê²ƒë“¤ì„ ìˆ˜ì •í•´ì„œ ì‚¬ìš©í•˜ì‹œë©´ ë©ë‹ˆë‹¤
    ~~~