# Pytorch_model_template

Note : ë§¨ ì•„ë˜ ì‹¤í—˜ ê²°ê³¼ë¥¼ ì—…ë¡œë“œí–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì£¼ì— ì½”ë“œë¥¼ ì—…ë¡œë“œí•  ê³„íšì…ë‹ˆë‹¤.(22/5/11 ì‘ì„±)

ì œì‘ì : ê¹€ë¯¼ê·œ <br>
ë¦¬í¬ì§€í† ë¦¬ ìƒì„±ì¼ : 22.4.16

## ì„¤ëª…
íŒŒì´í† ì¹˜ë¥¼ ì´ìš©í•´ ì œì‘í•œ ë„¤íŠ¸ì›Œí¬(MLP, CNN ë“±)ë“¤ì„ ì‰½ê²Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì œì‘í•˜ëŠ” í…œí”Œë¦¿. <br>
22.4.16 ê¸°ì¤€ìœ¼ë¡œ 3ê°€ì§€ ìœ í˜•(Linear, CNN, residual CNN)ì˜ ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

* util.py : ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” í•¨ìˆ˜ë“¤ì„ ëª¨ì•˜ìŠµë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ íŒŒì¼ì— ì í˜€ìˆëŠ” ì£¼ì„ì„ ì°¸ê³ í•˜ì‹œë©´ ë©ë‹ˆë‹¤.

## êµ¬ì„±(22.4.18 ê¸°ì¤€)
ğŸ“ main <br>
â””ğŸ“Basic_model <br>
â €â””normal_MLP.py <br>
â””ğŸ“Image_Classification <br>
â €â””ğŸ“CNN <br>
â €â €â””normal_CNN.py <br>
â €â €â””residual_CNN.py <br>
â €â””ğŸ“Linear <br>
â €â €â””MLP_Mixer.py <br>
â””ğŸ“util <br>
â €â””util.py <br>

### **<1> Basic model**
ê°€ì¥ ê¸°ë³¸ì ì¸ MLPê°€ ìˆìŠµë‹ˆë‹¤. 

1. Linear : ì„ í˜• ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” nn.Linear ë ˆì´ì–´ë¥¼ ê°€ì§€ê³  êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Basic_model.normal_MLP import *
 
    model = normal_MLP(input_size = 64, neural_list = [64, 64, 128, 128],  mid_activation_func = 'leaky_relu',  last_activateion_func = 'softmax', batch_normalization_use = False)
    ~~~

### **<2> Image Classification**
ì´ë¯¸ì§€ì— ì¡´ì¬í•˜ëŠ” ê°ì²´ì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì¼ì„ ìˆ˜í–‰í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ë¥¼ êµ¬í˜„í–ˆìŠµë‹ˆë‹¤. 

#### **<2-1> CNN**
CNNìœ¼ë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ë“¤ì…ë‹ˆë‹¤. 

1. normal_CNN : Covolution ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” CNN ì¤‘ ê°€ì¥ ê¸°ë³¸ì ì¸ í˜•íƒœë¥¼ ê°€ì§„ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤. <br> 
   ì‚¬ìš© ì˜ˆ)
    ~~~python
    # ì¼ë°˜ì ì¸ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.normal_CNN import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224) # ë„¤íŠ¸ì›Œí¬ì— ë„£ì„ ì´ë¯¸ì§€ì˜ í¬ê¸°
    kernal_list_normal_CNN = [16, 16,'p', 32, 32, 'p', 64, 64, 'p', 128, 128, 'p', 256, 256] # ìˆ«ìëŠ” Conv2dì˜ ì±„ë„ ê°œìˆ˜, 'p'ëŠ” poolingì„ ì˜ë¯¸í•©ë‹ˆë‹¤
    classes_num = 10 # ë¶„ë¥˜í•  í´ë˜ìŠ¤ ê°œìˆ˜

    normal_cnn = normal_CNN(input_size = image_size, kernal_list = kernal_list_normal_CNN, num_classes = classes_num, activation_func = 'relu', batch_normalization_use = True, device = 'cuda')


    ~~~
2. residual_CNN : Skip connectionì„ ìˆ˜í–‰í•˜ëŠ” CNNì…ë‹ˆë‹¤. ResNetì—ì„œ ì œì•ˆí•œ residual blockì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    ~~~python
    # Residual CNN, ê·¸ëŸ¬ë‹ˆê¹Œ ResNet ê³„ì—´ì˜ CNNì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°
    from Image_Classification.CNN.residual_CNN import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224)
    kernal_list_residual_CNN = [32, 32, 64, 64, 64, 64, 128, 128, 128]
    classes_num = 10
    
    residual_cnn = residual_CNN(input_size = image_size, kernal_list = kernal_list_residual_CNN, num_classes = classes_num, Residual_Block_size = 'small')

    ~~~


#### **<2-2> Linear**
MLPë¡œ êµ¬í˜„í•œ ë„¤íŠ¸ì›Œí¬ì…ë‹ˆë‹¤.

1. MLP-Mixer : MLPë§Œ ê°€ì§€ê³  ì´ë¯¸ì§€ì˜ classificationì„ ìˆ˜í–‰í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ìì„¸í•œ ì„¤ëª…ì€ MLP.MLP_Mixer.pyì— ìˆìŠµë‹ˆë‹¤. <br> ì‚¬ìš© ì˜ˆ)
    ~~~python
    from Linear.MLP_Mixer import *

    # ì‚¬ìš© ì˜ˆ
    image_size = (3, 224, 224)
    mlp_mixer = MLP_Mixer(input_size=image_size, patch_size=4, C=128, N=6, classes_num=classes_num).to('cuda')
    ~~~

## ì‹¤í—˜ ì„¸íŒ…

ì•„ë˜ ì¡°ê±´ì„ ê¸°ë°˜ìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•˜ëŠ” ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤. 
> ì‹¤í—˜ì„ ìˆ˜í–‰í•œ ì½”ë“œëŠ” model.ipynbì´ë¯€ë¡œ ìì„¸í•œ ì •ë³´ëŠ” í•´ë‹¹ ì£¼í”¼í„° ë…¸íŠ¸ë¶  íŒŒì¼ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<br>

### Training setting

~~~python
# Optimizer : Adam
optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-4)
# Gradient Cliping
torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
# Epoch
EPOCH = 600
# Loss function
loss_function = torch.nn.CrossEntropyLoss()
~~~

<br>

### Dataset : CIFAR 10(train, test)
~~~python
batch_size = 500

transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

train_dataset = torchvision.datasets.CIFAR10(root='./cifar', train=True, download=True, transform=transform)
test_dataset = torchvision.datasets.CIFAR10(root='./cifar', train=False, download=True, transform=transform)

train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=False, drop_last=True)

test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=6,pin_memory=False, drop_last=True)
~~~

<br>

### Model ì •ë³´

1. normal_cnn : ì¼ë°˜ì ì¸ êµ¬ì¡°ë¥¼ ê°€ì§€ëŠ” CNN
2. residual_cnn : Residual blockìœ¼ë¡œ ì„¤ê³„ëœ CNN
3. mlp_mixer_S4 : Image patchê°€ (4,4)ê³  Cë¥¼ 128ë¡œ ì„¤ì •í•œ MLP-Mixer
4. mlp_mixer_S2 : Image patchê°€ (2,2)ê³  Cë¥¼ 128ë¡œ ì„¤ì •í•œ MLP-Mixer
5. mlp_mixer_B4 : Image patchê°€ (4,4)ê³  Cë¥¼ 192ë¡œ ì„¤ì •í•œ MLP-Mixer
6. mlp_mixer_B2 : Image patchê°€ (2,2)ê³  Cë¥¼ 192ë¡œ ì„¤ì •í•œ MLP-Mixer

<br>

### Model Parameter ì •ë³´

| model        | parameter_num |
|--------------|---------------|
| normal_cnn   | 1,183,322       |
| residual_cnn | 1,134,026       |
| mlp_mixer_S4 | 273,674        |
| mlp_mixer_S2 | 1,062,026       |
| mlp_mixer_B4 | 698,186        |
| mlp_mixer_B2 | 1,756,106       |

<br>

## ì‹¤í—˜ ê²°ê³¼

<img width="910" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-30 á„‹á…©á„’á…® 5 12 02" src="https://user-images.githubusercontent.com/50979281/166097671-4b8d3b73-d323-4557-9fff-c0a1decaad4f.png">

<br>

<img width="913" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-04-30 á„‹á…©á„’á…® 5 12 13" src="https://user-images.githubusercontent.com/50979281/166097668-07357d0d-66db-4359-9a53-357a870d4ae1.png">

normal_cnnì´ ì œì¼ ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ê°œì¸ì ìœ¼ë¡œ ìƒê°í•˜ëŠ” ì›ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤. 

1. ì‚¬ì „í•™ìŠµì„ ìˆ˜í–‰í•˜ì§€ ì•Šì•˜ë‹¤ : ë…¼ë¬¸ì— ì íŒ ì‹¤í—˜ ë°©ì‹ì€ 'ì‚¬ì „í•™ìŠµ -> fine tuning'ì´ì—ˆìŠµë‹ˆë‹¤. í—ˆë‚˜ ì €ëŠ” ì‚¬ì „í•™ìŠµì„ ìˆ˜í–‰í•˜ì§€ ì•Šê³  scratchë¶€í„° CIFARë¥¼ í•™ìŠµì‹œì¼°ì£ . ì‚¬ì „í•™ìŠµì˜ ì—­í• ì€ ê½¤ í¬ê¸° ë•Œë¬¸ì— ì‚¬ì „í•™ìŠµì„ í•˜ì§€ ì•Šì€ ì ì´ ê²°ê³¼ì— ë§ì€ ì˜í–¥ì„ ë¯¸ì³¤ë‹¤ê³  íŒë‹¨ë©ë‹ˆë‹¤.
2. parameterê°œìˆ˜ì— ë§ëŠ” ì ì ˆí•œ í•™ìŠµí™˜ê²½ì„ ì„¤ì •í•˜ì§€ ì•ŠìŒ : ì‹¤í—˜ì˜ ê°„í¸ì„±ì„ ìœ„í•´ ê³ ì •ëœ í•™ìŠµ í™˜ê²½ì—ì„œ 6ê°œ ë„¤íŠ¸ì›Œí¬ë¥¼ í•™ìŠµì‹œì¼°ìŠµë‹ˆë‹¤. ì´ ë•Œ ì„¤ì •í•œ í•™ìŠµí™˜ê²½ì´ normal_cnnì— ì í•©í•œ í•™ìŠµí™˜ê²½ì´ì—ˆê¸° ë•Œë¬¸ì— normal_cnnì— ê°€ì¥ ì í•©í•œ ê²°ê³¼ê°€ ë‚˜ì˜¨ ê²ƒìœ¼ë¡œ ìƒê°ë©ë‹ˆë‹¤. 
3. parameter ê°œìˆ˜ê°€ ë„ˆë¬´ ì ìŒ : ResNetì´ normal_cnnì— ë°€ë¦¬ëŠ” ê²ƒì„ ë³´ë©° í™•ì‹ í–ˆìŠµë‹ˆë‹¤. ResNetì´ ë¹›ì„ ë°œí•˜ëŠ” ìˆœê°„ì€ ImageNetê°™ì€ ê±°ëŒ€ ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ê³ ì ë§¤ìš° í° ëª¨ë¸ì„ ì„¤ê³„í•  ê²½ìš°ì…ë‹ˆë‹¤. ResNetì´ ì œì•ˆëœ ì´ìœ ëŠ” ë„ˆë¬´ ë§ì€ ë ˆì´ì–´ë¥¼ ê°€ì§€ëŠ” ë„¤íŠ¸ì›Œí¬ë¡œ í•™ìŠµì„ ì‹œí‚¬ ë•Œ ì—­ì „íŒŒ ê³¼ì •ì—ì„œ ë ˆì´ì–´ë¥¼ ê±°ì¹  ë•Œë§ˆë‹¤ gradientê°€ ì¡°ê¸ˆì”© ì‚¬ë¼ì§€ëŠ” ë¬¸ì œ(gradient ì†Œì‹¤)ë¡œ ì¸í•´ ëª¨ë“  ë ˆì´ì–´ê°€ í•™ìŠµì´ ì•ˆë˜ëŠ” í˜„ìƒì„ ë°©ì§€í•˜ê³ ì ì œì•ˆëœ ê²ƒì¸ë° gradient ì†Œì‹¤ì´ ë‚˜ì˜¤ë ¤ë©´ ì‚¬ìš©í•˜ëŠ” ë ˆì´ì–´ì˜ ê°œìˆ˜ê°€ ì—„ì²­ ë§ì•„ì•¼í•©ë‹ˆë‹¤. ì´ë§ì€ ì¦‰, í•™ìŠµì‹œí‚¬ parameterê°€ ì•„ì£¼ ë§ì•„ì•¼ í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤. 
ì œê°€ ìˆ˜í–‰í•œ ì‹¤í—˜ì€ gradient ì†Œì‹¤ì´ ì¼ì–´ë‚ ë§Œí¼ ë„¤íŠ¸ì›Œí¬ë“¤ì´ í¬ì§€ ì•Šì•˜ê¸°ì— ê¸°ë³¸ì ì¸ ë°©ì‹ì˜ cnnì´ ë³„ë‹¤ë¥¸ ë¬´ë¦¬ ì—†ì´ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì—¬ì¤„ ìˆ˜ ìˆì–´ ê°€ì¥ ë†’ì€ ì„±ëŠ¥ì„ ê¸°ë¡í•œê²Œ ì•„ë‹Œê°€ ìƒê°ë©ë‹ˆë‹¤.